{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd607a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from typing import Optional, Dict, List, Tuple, Iterable, Sized\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "\n",
    "# –ó–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º –∑–µ—Ä–Ω–∞\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4d884",
   "metadata": {},
   "source": [
    "# 1. PyTorch Lightning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3087b2",
   "metadata": {},
   "source": [
    "Pytorch Lightning - —ç—Ç–æ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ API –¥–ª—è PyTorch, —É–ø—Ä–æ—â–∞—é—â–µ–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π.\n",
    "\n",
    "–ï—Å—Ç—å 2 –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–æ–≥–æ API:\n",
    "1. –ß–µ—Ä–µ–∑ –±–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã LightningModule, LightningDataModule –∏ Trainer;\n",
    "2. –ß–µ—Ä–µ–∑ —Ñ–∞–±—Ä–∏–∫—É lightinig.Fabric;\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655087e",
   "metadata": {},
   "source": [
    "| –°–≤–æ–π—Å—Ç–≤–æ           | Classic Lightning | Lightning Fabric |\n",
    "| ----------------- | --- | --- |\n",
    "| **–¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è** | –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç `training_step` –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ callbacks –≤ `Trainer` | –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞–µ—Ç–µ–ª–µ–º |\n",
    "| **–û—Ç–ª–∏—á–∏—è –≤ –∫–æ–¥–µ**  | –¢—Ä–µ–±—É–µ—Ç –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª–∏ –æ—Ç `LightningModule` –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–µ—Ç–æ–¥–æ–≤ | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã - –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ –æ–±–µ—Ä–Ω—É—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã |\n",
    "| **–ì–∏–±–∫–æ—Å—Ç—å**   | –ú–µ–Ω—å—à–µ –≥–∏–±–∫–æ—Å—Ç–∏, `Trainer` —É–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ–º | –¢–∞–∫–∞—è –∂–µ, –∫–∞–∫ –≤ PyTorch |\n",
    "| **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?**  | –ë—ã—Å—Ç—Ä–æ–µ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ | –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–∞ –≥–∏–±–∫–æ—Å—Ç—å –∏–ª–∏ –Ω—É–∂–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º –ø—Ä–æ–µ–∫—Ç–µ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import lightning as L\n",
    "\n",
    "class SimpleFFN_Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, n_classes, hidden_dim, n_hidden_layers=1, activation=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, hidden_dim)] * n_hidden_layers, \n",
    "        )\n",
    "        self.output = nn.Linear(hidden_dim, n_classes)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.activation(self.input(x))\n",
    "        for layer in self.layers:\n",
    "            x = self.activation(layer(x))\n",
    "        probs = self.softmax(self.output(x))\n",
    "\n",
    "        return probs\n",
    "\n",
    "class WrappedModel(L.LightningModule):\n",
    "\n",
    "    def __init__(self, input_dim, n_classes, hidden_dim, n_hidden_layers=1, activation=nn.ReLU(), lr=1e-3):\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.classifier = SimpleFFN_Classifier(input_dim, n_classes, hidden_dim, n_hidden_layers=1, activation=nn.ReLU())\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    def training_step(self, batch, batch_idx, loader_idx=0):\n",
    "        x, labels = batch\n",
    "        probs = self.classifier(x)\n",
    "\n",
    "        loss = self.loss_fn(probs, labels)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.get('lr', 3e-4))\n",
    "    \n",
    "model = WrappedModel(10, 10, 16, 4)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    fast_dev_run=1,\n",
    "    max_time={},\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model, \n",
    "    train_dataloaders=None,\n",
    "    val_dataloaders=None,\n",
    "    datamodule=None,\n",
    "    ckpt_path=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on 4 GPUs\n",
    "trainer = L.Trainer(\n",
    "    devices=4,\n",
    "    accelerator=\"gpu\",\n",
    ")\n",
    "\n",
    "# 20+ helpful flags for rapid idea iteration\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    min_epochs=5,\n",
    "    overfit_batches=1\n",
    ")\n",
    "\n",
    "# access the state of the art techniques\n",
    "from lightning.pytorch.callbacks import StochasticWeightAveraging\n",
    "trainer = L.Trainer(callbacks=[StochasticWeightAveraging(swa_lrs=3e-2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63cceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(L.LightningDataModule):\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # called once on 1 device\n",
    "        df = pd.read_hdf('datasets/example.h5')\n",
    "        self.data = Dataset()\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # called on each device, \n",
    "        self.train, self.val, self.test = \\\n",
    "            torch.utils.data.random_split(self.data, [0.8, 0.1, 0.1])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test)\n",
    "\n",
    "    def on_exception(self, exception: BaseException) -> None:\n",
    "        pass\n",
    "\n",
    "    def teardown(self, stage: str) -> None:\n",
    "        return super().teardown(stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9dad2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleFFN_Classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m fabric = L.Fabric()\n\u001b[32m      5\u001b[39m fabric.launch()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mSimpleFFN_Classifier\u001b[49m()\n\u001b[32m      8\u001b[39m optimizer = torch.optim.SGD(model.parameters(), lr=\u001b[32m0.001\u001b[39m)\n\u001b[32m      9\u001b[39m model, optimizer = fabric.setup(model, optimizer)\n",
      "\u001b[31mNameError\u001b[39m: name 'SimpleFFN_Classifier' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "fabric = L.Fabric()\n",
    "\n",
    "model = SimpleFFN_Classifier()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "model, optimizer = fabric.setup(model, optimizer)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\n",
    "dataloader = fabric.setup_dataloaders(dataloader)\n",
    "\n",
    "model.train()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        fabric.backward(loss)\n",
    "        optimizer.step()\n",
    "        print(loss.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bec61",
   "metadata": {},
   "source": [
    "- **`Fabric(...)`**: –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä. –ó–¥–µ—Å—å –≤—ã –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é.\n",
    "  - `accelerator`: 'cpu', 'cuda', 'mps', 'tpu', 'auto'.\n",
    "  - `devices`: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤, —Å–ø–∏—Å–æ–∫ ID —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –∏–ª–∏ 'auto'.\n",
    "  - `strategy`: 'ddp', 'deepspeed' –∏ —Ç.–¥.\n",
    "  - `precision`: '64', '32', '16-mixed', 'bf16-mixed'.\n",
    "  \n",
    "- **`fabric.setup(model, optimizer)`**: –û–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–≤–∞–Ω –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—É—á–µ–Ω–∏—è.\n",
    "  \n",
    "- **`fabric.setup_dataloaders(...)`**: –û–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö.\n",
    "  \n",
    "- **`fabric.backward(loss)`**: –ó–∞–º–µ–Ω–∞ `loss.backward()`. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
    "  \n",
    "- **`fabric.print(...)`**: –ó–∞–º–µ–Ω–∞ `print()`. –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã–≤–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ (—Ä–∞–Ω–≥ 0).\n",
    "  \n",
    "- **`fabric.launch(function, *args)`**: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –∑–∞–ø—É—Å–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è. –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–¥–∞.\n",
    "  \n",
    "- **`fabric.save(path, state)`**: –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫, –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞—é—â–∞—è –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Å—Ä–µ–¥–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.\n",
    "  \n",
    "- **`fabric.all_gather(tensor)`**: –°–±–æ—Ä —Ç–µ–Ω–∑–æ—Ä–∞ —Å–æ –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee7323",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run on 2 GPUs with DDP strategy\n",
    "fabric run main_fabric.py --accelerator=cuda --devices=2\n",
    "\n",
    "# Run with 16-bit mixed precision\n",
    "fabric run main_fabric.py --accelerator=cuda --devices=1 --precision=16-mixed\n",
    "\n",
    "# Run on CPU\n",
    "fabric run main_fabric.py --accelerator=cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8696747",
   "metadata": {},
   "source": [
    "# 2. –†–µ–∞–ª–∏–∑—É–µ–º baseline –æ–±—É—á–µ–Ω–∏—è —Ç—Ä–∞—Å—Ñ–æ—Ä–º–µ—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "model = AutoModel.from_pretrained(\"google/mobilebert-uncased\")\n",
    "embeddings = deepcopy(model.embeddings)\n",
    "# https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "print(f'Using tokenizer of')\n",
    "print(f'Vocabulary size: {VOCAB_SIZE}')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            path: str,\n",
    "            tokenizer: AutoTokenizer,\n",
    "            source_columns: List[str],\n",
    "            target_columns: List[str] = None,\n",
    "            nrows = None,\n",
    "            max_len = 256,\n",
    "            padding_type = \"max_length\",\n",
    "            ):\n",
    "\n",
    "        self.source_columns = source_columns\n",
    "        self.target_columns = target_columns if target_columns else source_columns\n",
    "\n",
    "        columns = source_columns\n",
    "        if target_columns:\n",
    "            columns += target_columns\n",
    "        \n",
    "        data = pd.read_csv(path, usecols=list(set(columns)), nrows=nrows)\n",
    "\n",
    "        self.src_ = []\n",
    "        self.tgt_ = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.CLS_id = tokenizer.cls_token_id\n",
    "        self.SEP_id = tokenizer.sep_token_id\n",
    "        self.PAD_idx = tokenizer.pad_token_id\n",
    "        self.max_len = max_len\n",
    "        self.padding_type = padding_type\n",
    "\n",
    "        for i in tqdm.trange(len(data)):\n",
    "            row = data.iloc[i]\n",
    "            src_text = self.process_row(row, source_columns)\n",
    "            self.src_.append(src_text)\n",
    "            \n",
    "            if target_columns is not None:\n",
    "                tgt_text = self.process_row(row, target_columns) \n",
    "                self.tgt_.append(tgt_text)\n",
    "        \n",
    "        if target_columns is None:\n",
    "            self.tgt_ = self.src_\n",
    "        \n",
    "        self.size = len(self.src_)\n",
    "\n",
    "    def process_row(self, row: pd.Series, columns: List[str]):\n",
    "        \"\"\"Processes a single recipe row from the DataFrame into a clean string.\"\"\"\n",
    "        entry_parts = []\n",
    "        for col in columns:\n",
    "            if pd.notna(row[col]):\n",
    "                content = str(row[col])\n",
    "                if content.startswith('[') and content.endswith(']'):\n",
    "                    content = re.sub(r'[\"\\\\$$\\\\\\\\$$]', '', content)\n",
    "                entry_parts.append(f'{col.replace(\"_\", \" \")}: {content}')\n",
    "                entry_parts.append('\\n')\n",
    "        return ''.join(entry_parts[:-1])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[str, str]:\n",
    "        source = self.src_[idx]\n",
    "        target = self.tgt_[idx]\n",
    "        return source, target\n",
    "\n",
    "    def single(self, idx):\n",
    "        return self.collate_fn([(self.src_[idx], self.tgt_[idx])])\n",
    "\n",
    "    def collate_fn(self, batch: List[Tuple[str, str]]) -> Dict[str, List]:\n",
    "        \n",
    "        sources = [f[0] for f in batch]\n",
    "        targets = [f[1] for f in batch]\n",
    "    \n",
    "        source_enc = self.tokenizer(list(sources), max_length=self.max_len, \n",
    "                                    padding=self.padding_type, truncation=True, \n",
    "                                    return_tensors=\"pt\").to(device=self.device)\n",
    "\n",
    "        target_enc = self.tokenizer(list(targets), max_length=self.max_len,\n",
    "                                    padding=self.padding_type, truncation=True, \n",
    "                                    return_tensors=\"pt\").to(device=self.device)\n",
    "        return {\n",
    "            'input_ids': source_enc['input_ids'], \n",
    "            'input_mask': source_enc['attention_mask'],\n",
    "            'input_lengths': source_enc['attention_mask'].sum(dim=-1),\n",
    "            'labels': target_enc['input_ids'],\n",
    "            'labels_mask': target_enc['attention_mask'],\n",
    "            'labels_lengths': target_enc['attention_mask'].sum(dim=-1),   \n",
    "            }\n",
    "\n",
    "    def get_loaders(\n",
    "            self,\n",
    "            names: Optional[List[str]] = ['train', 'val'],\n",
    "            ratios: Optional[List[float]] = [0.9, 0.1],\n",
    "            shuffle: Optional[List[bool]] = [True, False],\n",
    "            batch_size: int = 8,\n",
    "            load_ratio: int = 1.0,\n",
    "            **kwargs,\n",
    "        ) -> Dict[str, DataLoader]:\n",
    "        \"\"\"\n",
    "        Fetches several dataloaders from this dataset\n",
    "        \"\"\" \n",
    "\n",
    "        indices = list(range(len(self)))\n",
    "        i0 = 0\n",
    "        dataloaders: Dict[str, DataLoader] = {}\n",
    "        \n",
    "        for name, part, shuff in zip(names, ratios, shuffle):\n",
    "            part_len = int(len(indices) * part * load_ratio )\n",
    "            subset = Subset(self, indices[i0: i0 + part_len])\n",
    "            dataloaders[name] = DataLoader(subset, batch_size, shuff, collate_fn=self.collate_fn, **kwargs)\n",
    "            i0 += part_len        \n",
    "            \n",
    "        return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/1_Recipe_csv.csv'\n",
    "NSAMPLES = 48000\n",
    "\n",
    "copy_dataset = RecipeDataset(DATA_PATH, tokenizer, ['description', 'ingredients'], None,\\\n",
    "                     nrows=NSAMPLES, padding_type=\"longest\", device='cpu')\n",
    "\n",
    "ingredients_dataset = RecipeDataset(DATA_PATH, tokenizer, ['recipe_title', 'description'], ['ingredients'],\\\n",
    "                     nrows=NSAMPLES, padding_type=\"longest\", device='cpu')\n",
    "\n",
    "recipe_dataset = RecipeDataset(DATA_PATH, tokenizer, ['recipe_title', 'description'], ['ingredients'],\\\n",
    "                     nrows=NSAMPLES, padding_type=\"longest\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–ª–∞—Å—Å –º–æ–¥–µ–ª–∏\n",
    "\n",
    "class RecipeTransformer(L.LightningModule): ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c29291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é L.Trainer()\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
