{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Iterable, Sized\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "\n",
    "# Зафиксируем зерна\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "class logger:\n",
    "    active = False\n",
    "    _calls_ = {}\n",
    "    log_file = \"logger_output.txt\"  # по умолчанию\n",
    "    silent = True\n",
    "\n",
    "    @classmethod\n",
    "    @contextmanager\n",
    "    def log(cls):\n",
    "\n",
    "        cls.clear_log()\n",
    "        cls.zero()\n",
    "        cls.on()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            cls.off()\n",
    "    \n",
    "    @classmethod\n",
    "    def on(cls): cls.active = True\n",
    "\n",
    "    @classmethod\n",
    "    def off(cls): cls.active = False\n",
    "\n",
    "    @classmethod\n",
    "    def silent(cls, silent: bool = True):\n",
    "        cls.silent = silent\n",
    "\n",
    "    @classmethod\n",
    "    def zero(cls):\n",
    "        cls._calls_ = {}\n",
    "\n",
    "    @classmethod\n",
    "    def clear_log(cls):\n",
    "        with open(cls.log_file, 'w') as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "    @classmethod\n",
    "    def write_log(cls, msg):\n",
    "        with open(cls.log_file, 'a') as f:\n",
    "            f.write(msg + \"\\n\")\n",
    "\n",
    "    @classmethod\n",
    "    def trace(cls, name):\n",
    "        def log_fn(func):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                if cls.active:\n",
    "                    if name not in cls._calls_:\n",
    "                        cls._calls_[name] = 0\n",
    "                    msg = f'>>> {name} call {cls._calls_[name]}: \\n Args: \\n'\n",
    "                    for i, arg in enumerate(args):\n",
    "                        if isinstance(arg, torch.Tensor):\n",
    "                            msg += f'\\t arg[{i}]: shape={arg.shape}, dtype={arg.dtype}, device={arg.device}\\n {arg} \\n'\n",
    "                        else:\n",
    "                            msg += f'\\t arg[{i}]: {arg}\\n'\n",
    "\n",
    "                    for k, arg in kwargs.items():\n",
    "                        if isinstance(arg, torch.Tensor):\n",
    "                            msg += f'\\t kwarg[{k}]: shape={arg.shape}, dtype={arg.dtype}, device={arg.device}\\n {arg} \\n'\n",
    "                        else:\n",
    "                            msg += f'\\t kwarg[{k}]: {arg} \\n'\n",
    "\n",
    "                    if not cls.silent: print(msg)\n",
    "                    cls.write_log(msg)\n",
    "\n",
    "                result = func(*args, **kwargs)\n",
    "\n",
    "                if cls.active:\n",
    "                    msg = f'Result: \\n'\n",
    "                    if isinstance(result, Iterable):\n",
    "                        for i, outp in enumerate(result):\n",
    "                            if isinstance(outp, torch.Tensor):\n",
    "                                msg += f'\\t output[{i}]: shape={outp.shape}, dtype={outp.dtype}, device={outp.device}\\n {outp} \\n'\n",
    "                            else:\n",
    "                                msg += f'\\t output[{i}]: {outp}\\n'\n",
    "                    elif isinstance(result, torch.Tensor):\n",
    "                        msg = f'\\t output: shape={result.shape}, dtype={result.dtype}, device={result.device}\\n {result} \\n'\n",
    "                    else:\n",
    "                        msg += f'\\t output: {result}\\n'\n",
    "\n",
    "                    if not cls.silent: print(msg)\n",
    "                    cls.write_log(msg)\n",
    "                    cls._calls_[name] += 1\n",
    "\n",
    "                return result\n",
    "            return wrapper\n",
    "\n",
    "        return log_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE3a4sgdCQPr"
   },
   "source": [
    "# 1. Токенизатор и эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniconda3/envs/nn_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniconda3/envs/nn_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mobilebert = AutoModel.from_pretrained(\"google/mobilebert-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "MobileBertModel                                              --\n",
       "├─MobileBertEmbeddings: 1-1                                  --\n",
       "│    └─Embedding: 2-1                                        3,906,816\n",
       "│    └─Embedding: 2-2                                        262,144\n",
       "│    └─Embedding: 2-3                                        1,024\n",
       "│    └─Linear: 2-4                                           197,120\n",
       "│    └─NoNorm: 2-5                                           1,024\n",
       "│    └─Dropout: 2-6                                          --\n",
       "├─MobileBertEncoder: 1-2                                     --\n",
       "│    └─ModuleList: 2-7                                       --\n",
       "│    │    └─MobileBertLayer: 3-1                             842,240\n",
       "│    │    └─MobileBertLayer: 3-2                             842,240\n",
       "│    │    └─MobileBertLayer: 3-3                             842,240\n",
       "│    │    └─MobileBertLayer: 3-4                             842,240\n",
       "│    │    └─MobileBertLayer: 3-5                             842,240\n",
       "│    │    └─MobileBertLayer: 3-6                             842,240\n",
       "│    │    └─MobileBertLayer: 3-7                             842,240\n",
       "│    │    └─MobileBertLayer: 3-8                             842,240\n",
       "│    │    └─MobileBertLayer: 3-9                             842,240\n",
       "│    │    └─MobileBertLayer: 3-10                            842,240\n",
       "│    │    └─MobileBertLayer: 3-11                            842,240\n",
       "│    │    └─MobileBertLayer: 3-12                            842,240\n",
       "│    │    └─MobileBertLayer: 3-13                            842,240\n",
       "│    │    └─MobileBertLayer: 3-14                            842,240\n",
       "│    │    └─MobileBertLayer: 3-15                            842,240\n",
       "│    │    └─MobileBertLayer: 3-16                            842,240\n",
       "│    │    └─MobileBertLayer: 3-17                            842,240\n",
       "│    │    └─MobileBertLayer: 3-18                            842,240\n",
       "│    │    └─MobileBertLayer: 3-19                            842,240\n",
       "│    │    └─MobileBertLayer: 3-20                            842,240\n",
       "│    │    └─MobileBertLayer: 3-21                            842,240\n",
       "│    │    └─MobileBertLayer: 3-22                            842,240\n",
       "│    │    └─MobileBertLayer: 3-23                            842,240\n",
       "│    │    └─MobileBertLayer: 3-24                            842,240\n",
       "├─MobileBertPooler: 1-3                                      --\n",
       "=====================================================================================\n",
       "Total params: 24,581,888\n",
       "Trainable params: 24,581,888\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(mobilebert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_word_embedding = deepcopy(mobilebert.embeddings.word_embeddings)\n",
    "del mobilebert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 128])\n"
     ]
    }
   ],
   "source": [
    "print(bert_word_embedding.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "print(f'Vocabulary size: {VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS token  is not present in tokenizer\n",
      "EOS token  is not present in tokenizer\n",
      "PAD token: token [PAD], id 0\n",
      "UNK token: token [UNK], id 100\n",
      "SEP token: token [SEP], id 102\n",
      "CLS token: token [CLS], id 101\n"
     ]
    }
   ],
   "source": [
    "def collect_special_tokens(tokenizer: AutoTokenizer) -> Dict:\n",
    "\n",
    "    special_tokens = ['PAD', 'BOS', 'EOS', 'UNK', 'SEP', 'CLS']\n",
    "    outp = {}\n",
    "    for name in special_tokens:\n",
    "        token = getattr(tokenizer, f'{name.lower()}_token')\n",
    "        if token is not None:\n",
    "            outp[name] = token\n",
    "            outp[f'{name}_id'] = getattr(tokenizer, f'{name.lower()}_token_id')\n",
    "        else:\n",
    "            print(f'{name} token  is not present in tokenizer')\n",
    "    \n",
    "    for name in special_tokens:\n",
    "        if name in outp:\n",
    "            print(f'{name} token: token {outp[name]}, id {outp[f'{name}_id']}')\n",
    "\n",
    "    return outp\n",
    "\n",
    "special_tokens = collect_special_tokens(tokenizer)\n",
    "\n",
    "for k, v in special_tokens.items():\n",
    "    globals()[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем использовать CLS в качестве BOS и SEP в качестве EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 17953, 2361, 1006, 11265, 10976, 1011, 12158, 4730, 1007, 2003, 1037, 8317, 3921, 2008, 7336, 20253, 1996, 7060, 1997, 2245, 1010, 2653, 1010, 1998, 5248, 2000, 3305, 2129, 2027, 11835, 2007, 1998, 3747, 2529, 3325, 1012, 2045, 2003, 2053, 4045, 3350, 4637, 1996, 12353, 1997, 17953, 2361, 1025, 2009, 2003, 3858, 2004, 1037, 18404, 11020, 13684, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[CLS] nlp ( neuro - linguistic programming ) is a psychological approach that involves analyzing the patterns of thought, language, and behavior to understand how they interact with and influence human experience. there is no scientific evidence supporting the effectiveness of nlp ; it is recognized as a pseudoscience. [SEP]\n"
     ]
    }
   ],
   "source": [
    "text = 'NLP (Neuro-Linguistic Programming) is a psychological approach that involves analyzing the patterns of thought, language, and behavior to understand how they interact with and influence human experience. There is no scientific evidence supporting the effectiveness of NLP; it is recognized as a pseudoscience.'\n",
    "# apply tokenizer:\n",
    "seq = tokenizer(text)\n",
    "print(seq)\n",
    "# decode with tokenizer:\n",
    "print(tokenizer.decode(seq['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 17953,  2361,  1006, 11265, 10976,  1011, 12158,  4730,  1007,\n",
      "          2003,  1037,  8317,  3921,  2008,  7336, 20253,  1996,  7060,  1997,\n",
      "          2245,  1010,  2653,  1010,  1998,  5248,  2000,  3305,  2129,  2027,\n",
      "         11835,  2007,  1998,  3747,  2529,  3325,  1012,  2045,  2003,  2053,\n",
      "          4045,  3350,  4637,  1996, 12353,  1997, 17953,  2361,  1025,  2009,\n",
      "          2003,  3858,  2004,  1037, 18404, 11020, 13684,  1012,   102,     0,\n",
      "             0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]), 'length': tensor([64])}\n",
      "[CLS] nlp ( neuro - linguistic programming ) is a psychological approach that involves analyzing the patterns of thought, language, and behavior to understand how they interact with and influence human experience. there is no scientific evidence supporting the effectiveness of nlp ; it is recognized as a pseudoscience. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "texts = ['NLP (Neuro-Linguistic Programming) is a psychological approach that involves analyzing the patterns of thought, language, and behavior to understand how they interact with and influence human experience.',\n",
    "         'There is no scientific evidence supporting the effectiveness of NLP; it is recognized as a pseudoscience.']\n",
    "seq = tokenizer(text, max_length=64, padding=\"max_length\",\\\n",
    "                truncation=\"longest_first\", return_tensors=\"pt\",\\\n",
    "                return_token_type_ids = False, return_length=True)\n",
    "print(seq)\n",
    "# decode with tokenizer:\n",
    "print(tokenizer.decode(seq['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Возвращается не словарь, а свой тип, имеющий  методы Dict() и другие \n",
    "type(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] nl ##p ( ne ##uro - linguistic programming ) is a psychological approach that involves analyzing the patterns of thought , language , and behavior to understand how they interact with and influence human experience . there is no scientific evidence supporting the effectiveness of nl ##p ; it is recognized as a pseudo ##sc ##ience . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(*seq.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_MutableMapping__marker   __abstractmethods__   __class__   __class_getitem__   __contains__   __copy__   __delattr__   __delitem__   __dict__   __dir__   __doc__   __eq__   __format__   __ge__   __getattr__   __getattribute__   __getitem__   __getstate__   __gt__   __hash__   __init__   __init_subclass__   __ior__   __iter__   __le__   __len__   __lt__   __module__   __ne__   __new__   __or__   __reduce__   __reduce_ex__   __repr__   __reversed__   __ror__   __setattr__   __setitem__   __setstate__   __sizeof__   __slots__   __str__   __subclasshook__   __weakref__   _abc_impl   _encodings   _n_sequences   char_to_token   char_to_word   clear   convert_to_tensors   copy   data   encodings   fromkeys   get   is_fast   items   keys   n_sequences   pop   popitem   sequence_ids   setdefault   to   token_to_chars   token_to_sequence   token_to_word   tokens   update   values   word_ids   word_to_chars   word_to_tokens   words   \n"
     ]
    }
   ],
   "source": [
    "print(''.join([_attr_+'   ' for _attr_ in dir(seq)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 17953,  2361,  1006, 11265, 10976,  1011, 12158,  4730,  1007,\n",
      "          2003,  1037,  8317,  3921,  2008,  7336, 20253,  1996,  7060,  1997,\n",
      "          2245,  1010,  2653,  1010,  1998,  5248,  2000,  3305,  2129,  2027,\n",
      "         11835,  2007,  1998,  3747,  2529,  3325,  1012,  2045,  2003,  2053,\n",
      "          4045,  3350,  4637,  1996, 12353,  1997, 17953,  2361,  1025,  2009,\n",
      "          2003,  3858,  2004,  1037, 18404, 11020, 13684,  1012,   102,     0,\n",
      "             0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(seq.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjcEKe88CU6I"
   },
   "source": [
    "# 2. Данные и контейнеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data directory: ../data\n",
      "Found dataset: ../data/1_Recipe_csv.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "data_dir=\"../data\"\n",
    "csv_name=\"1_Recipe_csv.csv\"\n",
    "zip_name=\"recipes-dataset-64k.zip\"\n",
    "zip_path=\"$data_dir/$zip_name\"\n",
    "\n",
    "if [ ! -d \"$data_dir\" ]; then\n",
    "    mkdir -p \"$data_dir\"\n",
    "    echo \"Directory created: $data_dir\"\n",
    "else\n",
    "    echo \"Found data directory: $data_dir\"\n",
    "fi\n",
    "\n",
    "if [ ! -f \"$data_dir/$csv_name\" ]; then\n",
    "    echo \"CSV file $csv_name not found...\"\n",
    "    if [ ! -f \"$zip_path\" ]; then\n",
    "        echo \"Archive $zip_name not found, downloading...\"\n",
    "        curl -L -o \"$zip_path\" https://www.kaggle.com/api/v1/datasets/download/prashantsingh001/recipes-dataset-64k-dishes\n",
    "        echo \"Dataset downloaded: $zip_path\"\n",
    "    else\n",
    "        echo \"Found archive $zip_name\"\n",
    "    fi\n",
    "    echo \"Extracting to $data_dir ...\"\n",
    "    unzip \"$zip_path\" -d \"$data_dir\"\n",
    "    echo \"Dataset unzipped to: $data_dir\"\n",
    "else\n",
    "    echo \"Found dataset: $data_dir/$csv_name\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            path: str,\n",
    "            tokenizer: AutoTokenizer,\n",
    "            source_columns: List[str],\n",
    "            target_columns: List[str] = None,\n",
    "            nrows = None,\n",
    "            device = 'cpu',\n",
    "            max_len = 256,\n",
    "            padding_type = \"max_length\",\n",
    "            ):\n",
    "\n",
    "        self.source_columns = source_columns\n",
    "        self.target_columns = target_columns if target_columns else source_columns\n",
    "\n",
    "        columns = source_columns\n",
    "        if target_columns:\n",
    "            columns += target_columns\n",
    "        \n",
    "        data = pd.read_csv(path, usecols=list(set(columns)), nrows=nrows)\n",
    "\n",
    "        self.src_ = []\n",
    "        self.tgt_ = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.CLS_id = tokenizer.cls_token_id\n",
    "        self.SEP_id = tokenizer.sep_token_id\n",
    "        self.device = device\n",
    "        self.PAD_idx = tokenizer.pad_token_id\n",
    "        self.max_len = max_len\n",
    "        self.padding_type = padding_type\n",
    "\n",
    "        for i in tqdm.trange(len(data)):\n",
    "            row = data.iloc[i]\n",
    "            src_text = self.process_row(row, source_columns)\n",
    "            self.src_.append(src_text)\n",
    "            \n",
    "            if target_columns is not None:\n",
    "                tgt_text = self.process_row(row, target_columns) \n",
    "                self.tgt_.append(tgt_text)\n",
    "        \n",
    "        if target_columns is None:\n",
    "            self.tgt_ = self.src_\n",
    "        \n",
    "        self.size = len(self.src_)\n",
    "\n",
    "    def process_row(self, row: pd.Series, columns: List[str]):\n",
    "        \"\"\"Processes a single recipe row from the DataFrame into a clean string.\"\"\"\n",
    "        entry_parts = []\n",
    "        for col in columns:\n",
    "            if pd.notna(row[col]):\n",
    "                content = str(row[col])\n",
    "                if content.startswith('[') and content.endswith(']'):\n",
    "                    content = re.sub(r'[\"\\\\$$\\\\\\\\$$]', '', content)\n",
    "                entry_parts.append(f'{col.replace(\"_\", \" \")}: {content}')\n",
    "                entry_parts.append('\\n')\n",
    "        return ''.join(entry_parts[:-1])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[str, str]:\n",
    "        source = self.src_[idx]\n",
    "        target = self.tgt_[idx]\n",
    "        return source, target\n",
    "\n",
    "    def to(self, device='cpu', dtype=None):\n",
    "        \n",
    "        if device is not None:\n",
    "            if self.device != device:\n",
    "                clone = deepcopy(self)\n",
    "                clone.device = device\n",
    "                return clone\n",
    "            else:\n",
    "                return self\n",
    "        # if dtype is not None:\n",
    "        #     return self\n",
    "\n",
    "    def single(self, idx):\n",
    "        return self.collate_fn([(self.src_[idx], self.tgt_[idx])])\n",
    "\n",
    "    def collate_fn(self, batch: List[Tuple[str, str]]) -> Dict[str, List]:\n",
    "        \n",
    "        sources = [f[0] for f in batch]\n",
    "        targets = [f[1] for f in batch]\n",
    "    \n",
    "        source_enc = self.tokenizer(list(sources), max_length=self.max_len, \n",
    "                                    padding=self.padding_type, truncation=True, \n",
    "                                    return_tensors=\"pt\").to(device=self.device)\n",
    "\n",
    "        target_enc = self.tokenizer(list(targets), max_length=self.max_len,\n",
    "                                    padding=self.padding_type, truncation=True, \n",
    "                                    return_tensors=\"pt\").to(device=self.device)\n",
    "        return {\n",
    "            'input_ids': source_enc['input_ids'], \n",
    "            'input_mask': source_enc['attention_mask'],\n",
    "            'input_lengths': source_enc['attention_mask'].sum(dim=-1),\n",
    "            'labels': target_enc['input_ids'],\n",
    "            'labels_mask': target_enc['attention_mask'],\n",
    "            'labels_lengths': target_enc['attention_mask'].sum(dim=-1),   \n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48000/48000 [00:00<00:00, 90325.58it/s]\n",
      "100%|██████████| 48000/48000 [00:00<00:00, 60403.44it/s]\n",
      "100%|██████████| 48000/48000 [00:00<00:00, 59987.11it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../data/1_Recipe_csv.csv'\n",
    "NSAMPLES = 48000\n",
    "\n",
    "copy_dataset = RecipeDataset(DATA_PATH, tokenizer, ['description', 'ingredients'], None,\\\n",
    "                     nrows=NSAMPLES, padding_type=\"longest\", device='cpu')\n",
    "\n",
    "ingredients_dataset = RecipeDataset(DATA_PATH, tokenizer, ['recipe_title', 'description'], ['ingredients'],\\\n",
    "                     nrows=NSAMPLES, padding_type=\"longest\", device='cpu')\n",
    "\n",
    "recipe_dataset = RecipeDataset(DATA_PATH, tokenizer, ['recipe_title', 'description'], ['ingredients'],\\\n",
    "                     nrows=NSAMPLES, padding_type=\"longest\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: This chocolate Yule log is a festive holiday cake. Merry Christmas! You will need cinnamon red hard candies and snowmen candy for decorations.\n",
      "ingredients: [u00bd cup sifted cake flour, u00bc cup unsweetened cocoa powder, 1 teaspoon baking powder, u00bc teaspoon salt, u00bd cup white sugar, 3 large eggs, separated, u00bc cup milk, 2 tablespoons confectioners' sugar, 1 u00bd cups prepared whipped cream]\n",
      "description: This chocolate Yule log is a festive holiday cake. Merry Christmas! You will need cinnamon red hard candies and snowmen candy for decorations.\n",
      "ingredients: [u00bd cup sifted cake flour, u00bc cup unsweetened cocoa powder, 1 teaspoon baking powder, u00bc teaspoon salt, u00bd cup white sugar, 3 large eggs, separated, u00bc cup milk, 2 tablespoons confectioners' sugar, 1 u00bd cups prepared whipped cream]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, NSAMPLES)\n",
    "print(copy_dataset[idx][0])\n",
    "print(copy_dataset[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "Training set size: 384\n",
      "Validation set size: 48\n",
      "Test set size: 48\n",
      "Using batching with padding. Ensure your training loop can handle batched data!\n"
     ]
    }
   ],
   "source": [
    "def get_dataloaders(dataset: RecipeDataset,\n",
    "                    train_ratio=0.8,\n",
    "                    val_ratio=0.1,\n",
    "                    batch_size=1,\n",
    "                    load_ratio = 1.0,\n",
    "                    device='cpu',\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    Loads data, splits it, and creates train, validation, and test DataLoaders.\n",
    "    \"\"\"\n",
    "    indices = list(range(len(dataset)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    train_end = int(len(indices) * train_ratio * load_ratio)\n",
    "    val_end = int(len(indices) * (train_ratio + val_ratio) * load_ratio)\n",
    "    test_end = int(len(indices) * load_ratio)\n",
    "    \n",
    "    dataset = dataset.to(device=device)\n",
    "    collate_fn = dataset.collate_fn\n",
    "    train_set = Subset(dataset, indices[:train_end])\n",
    "    val_set = Subset(dataset, indices[train_end:val_end])\n",
    "    test_set = Subset(dataset, indices[val_end:test_end])\n",
    "\n",
    "    print(f\"Data split:\")\n",
    "    print(f\"Training set size: {len(train_set)}\")\n",
    "    print(f\"Validation set size: {len(val_set)}\")\n",
    "    print(f\"Test set size: {len(test_set)}\")\n",
    "\n",
    "    if batch_size >= 1:\n",
    "        print(\"Using batching with padding. Ensure your training loop can handle batched data!\")\n",
    "        \n",
    "    return {\n",
    "        'train':DataLoader(train_set, batch_size, shuffle=True, collate_fn=collate_fn), \n",
    "        'val': DataLoader(val_set, batch_size, shuffle=False, collate_fn=collate_fn), \n",
    "        'test': DataLoader(test_set, batch_size, shuffle=False, collate_fn=collate_fn),\n",
    "    }  \n",
    "\n",
    "dataloaders = get_dataloaders(ingredients_dataset, batch_size=16, load_ratio=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 17974,  2516,  ...,  2378,  1033,   102],\n",
      "        [  101, 17974,  2516,  ...,     0,     0,     0],\n",
      "        [  101, 17974,  2516,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17974,  2516,  ...,     0,     0,     0],\n",
      "        [  101, 17974,  2516,  ...,     0,     0,     0],\n",
      "        [  101, 17974,  2516,  ...,     0,     0,     0]]), 'input_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'input_lengths': tensor([222, 205,  97, 156, 140, 135, 109, 207, 157, 119, 134, 154, 104,  96,\n",
      "        174, 126]), 'labels': tensor([[  101, 12760,  1024,  ...,     0,     0,     0],\n",
      "        [  101, 12760,  1024,  ...,     0,     0,     0],\n",
      "        [  101, 12760,  1024,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 12760,  1024,  ...,     0,     0,     0],\n",
      "        [  101, 12760,  1024,  ...,     0,     0,     0],\n",
      "        [  101, 12760,  1024,  ...,     0,     0,     0]]), 'labels_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels_lengths': tensor([145, 140,  63,  83,  81,  62,  88, 173, 107,  73,  97, 102,  68,  56,\n",
      "        135, 101])}\n"
     ]
    }
   ],
   "source": [
    "batch_n = 1\n",
    "n = 0\n",
    "\n",
    "for X in dataloaders['test']:\n",
    "    if n == batch_n:\n",
    "         print(X)\n",
    "    elif n > batch_n:\n",
    "        break\n",
    "    n += 1      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pgpvoyMCuMq"
   },
   "source": [
    "# 3.1. Seq2seq без внимания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
    "    def __init__(self, input_size, output_size, num_layers=1, dropout_rate=0.0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.GRU(input_size, output_size, num_layers, \n",
    "                          batch_first=True, bidirectional=True)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "\n",
    "    @logger.trace('ENC')\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Applies a bidirectional GRU to sequence of embeddings x.\n",
    "\n",
    "        Args:\n",
    "            - x should have dimensions [batch, seq_len, emb_dim].\n",
    "        \"\"\"\n",
    "        x = self.dropout(x)\n",
    "        lengths = torch.IntTensor([x.shape[1] for _ in range(x.shape[0])]).cpu()\n",
    "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        \n",
    "        output, hidden = self.rnn(packed) # [B, SEQ_LEN, bidir*EMB_DIM], [N_layers*bidir, B, EMB_DIM], \n",
    "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
    "        # hidden = torch.cat((hidden[0, ...], hidden[1, ...]), dim=-1)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
    "    def __init__(self, context_size, hidden_size, enc_hidden, num_layers=1, \n",
    "                 dropout_rate=0.5, max_steps = 256, bridge=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.rnn = nn.GRU(context_size + hidden_size, hidden_size,\n",
    "                          num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        # Для инициализации из конечного состояния энкодера\n",
    "        self.bridge = nn.Linear(2*enc_hidden, hidden_size, bias=True) if bridge else nn.Ident()\n",
    "\n",
    "    @logger.trace('DEC')\n",
    "    def forward(self, context, prev, hidden=None, src_mask=None):\n",
    "        \"\"\"One step of the decoder.\n",
    "        Args:\n",
    "            - context: torch.Tensor [B, CONTEXT]\n",
    "            - prev: initial vector or prediction on previous step\n",
    "            - src_mask\n",
    "        \"\"\"\n",
    "        context = context.sum(dim=1) ## Attention will be here\n",
    "\n",
    "        x = torch.cat((context, prev), dim=-1).unsqueeze(1)\n",
    "        \n",
    "        output, hidden = self.rnn(x, hidden) \n",
    "        # [B, CON+HIDDEN*dec_bidir], [N_layers*dec_bidir, B, EMB_DIM], \n",
    "        return output.squeeze(1), hidden\n",
    "\n",
    "    @logger.trace('DEC_hid_init')\n",
    "    def init_hidden(self, encoder_hidden):\n",
    "\n",
    "        X = torch.cat((encoder_hidden[0, ...], encoder_hidden[1, ...]), dim=-1)\n",
    "        X = torch.tanh(self.bridge(X))\n",
    "        \n",
    "        return X.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Seq2Seq                                  --\n",
       "├─Embedding: 1-1                         (3,906,816)\n",
       "├─Encoder: 1-2                           --\n",
       "│    └─GRU: 2-1                          198,144\n",
       "│    └─Dropout: 2-2                      --\n",
       "├─Decoder: 1-3                           --\n",
       "│    └─GRU: 2-3                          197,376\n",
       "│    └─Dropout: 2-4                      --\n",
       "│    └─Linear: 2-5                       32,896\n",
       "├─Sequential: 1-4                        --\n",
       "│    └─Linear: 2-6                       16,512\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─Linear: 2-8                       (3,906,816)\n",
       "=================================================================\n",
       "Total params: 8,258,560\n",
       "Trainable params: 444,928\n",
       "Non-trainable params: 7,813,632\n",
       "================================================================="
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Seq2Seq architectue\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "            tokenizer, embedding,\n",
    "            hidden_size, n_layers, dropout_rate,\n",
    "            EncoderCls, DecoderCls,\n",
    "            max_steps=256, bridge=True, tie_projection=False,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - tokenizer: AutoTokenizer - input text tokenizer\n",
    "            - embedding: nn.Embedding - pre-trained embedding\n",
    "            - n_layers: number of layers in rnn\n",
    "            - cls: encoder class to use, must match signature (),\n",
    "            - decoder_cls: decoder class to use, must match signature (),\n",
    "            - tie_projection: bool - if true, embedding and projection layer will use same weights\n",
    "        \"\"\"\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.embedding = embedding\n",
    "        self.embed_dim = embedding.embedding_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.max_steps = max_steps\n",
    "        self.tie_projection = tie_projection\n",
    "        \n",
    "        self.CLS_id = torch.IntTensor([tokenizer.cls_token_id])\n",
    "        self.SEP_id = torch.IntTensor([tokenizer.sep_token_id])\n",
    "        self.vocab_size = tokenizer.vocab_size\n",
    "\n",
    "        self.EncoderCls = EncoderCls\n",
    "        self.DecoderCls = DecoderCls\n",
    "        \n",
    "        self.encoder = EncoderCls(self.embed_dim, hidden_size, n_layers, dropout_rate)\n",
    "        self.decoder = DecoderCls(hidden_size*2, self.embed_dim, hidden_size, n_layers, dropout_rate, bridge=bridge)\n",
    "        \n",
    "        self.comment = None\n",
    "        self.defaultpath = '../'\n",
    "\n",
    "        self.teacher_forcing = None\n",
    "\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        if tie_projection:\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Linear(self.embed_dim, self.embed_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.embed_dim, self.vocab_size, bias=False),\n",
    "                )\n",
    "            self.projection[-1].weight = self.embedding.weight\n",
    "        else:\n",
    "            self.projection = nn.Linear(self.embed_dim, self.vocab_size, bias=False)\n",
    "    \n",
    "    @logger.trace('MODEL')\n",
    "    def forward(self, tokens, src_lengths=None, src_mask=None, tgt_lenghts=None, tgt_mask=None, nsteps=None):\n",
    "        '''\n",
    "        Forward pass of the model\n",
    "        Args:\n",
    "            - tokens: torch.IntTensor of shape [batch, sequence_len]\n",
    "        Returns: dict\n",
    "        \n",
    "        '''\n",
    "        input_device = self.embedding.weight.device\n",
    "        if tokens.device != input_device:\n",
    "            tokens = tokens.to(device=input_device)\n",
    "            \n",
    "        batch_size = tokens.shape[0]\n",
    "        if nsteps == None: nsteps = self.max_steps\n",
    "        if tgt_lenghts != None: nsteps = min(nsteps, max(tgt_lenghts))\n",
    "\n",
    "        # Считываем токены в обратной последовательности, \n",
    "        # так RNN будет лучше помнить токены начала предложения\n",
    "        embed = self.embedding(tokens.flip(dims=[1]))\n",
    "        context, enc_hidden = self.encoder.forward(embed)\n",
    "        \n",
    "        # ID специальных токенов должны быть на том же устройстве(увы)\n",
    "        SEP, CLS = self.SEP_id.to(device=input_device), self.CLS_id.to(device=input_device)\n",
    "        \n",
    "        # Следующие величины понадобятся для цикла декодера \n",
    "        prev = self.embedding(CLS).repeat(batch_size, 1)\n",
    "        active = torch.ones(batch_size, dtype=torch.bool).to(device=input_device)\n",
    "    \n",
    "        logits = torch.zeros(batch_size, nsteps, self.vocab_size,\n",
    "                             dtype=prev.dtype).to(device=input_device)\n",
    "        pred_tokens = torch.zeros(batch_size, nsteps, dtype=tokens.dtype).to(device=input_device)\n",
    "        dec_hidden = self.decoder.init_hidden(enc_hidden)\n",
    "\n",
    "        last = nsteps        \n",
    "        for i in range(nsteps):\n",
    "            # Запускаем декодер    \n",
    "            dec_out, dec_hidden = self.decoder(context[active, ...], prev[active], hidden=dec_hidden) \n",
    "            \n",
    "            logits_ = F.log_softmax(self.projection(dec_out), dim=-1)\n",
    "            logits[active, i] += logits_\n",
    "            \n",
    "            _, idxs_ = logits_.max(dim=-1)\n",
    "            pred_tokens[active, i] = idxs_\n",
    "            \n",
    "            prev[active] = dec_out #[B_, EMB]\n",
    "            active[active].logical_and_(idxs_ != SEP)\n",
    "            \n",
    "            if not active.any():\n",
    "                last = i\n",
    "                break\n",
    "            if self.training and self.teacher_forcing:\n",
    "                prev = self.teacher_forcing(i, prev)\n",
    "                \n",
    "        return {\n",
    "            'tokens': pred_tokens[:, :last], \n",
    "            'logits': logits[:, :last, :],\n",
    "            }\n",
    "    \n",
    "    def predict(self, text, nsteps=128):\n",
    "\n",
    "        tokens = self.tokenizer(text, padding='longest', return_tensors='pt')\n",
    "        pred = model.forward(tokens['input_ids'], nsteps=nsteps)\n",
    "        output_text = self.tokenizer.batch_decode(sequences=pred['tokens'].cpu())\n",
    "        \n",
    "        return output_text\n",
    "\n",
    "model = Seq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    embedding=bert_word_embedding,\n",
    "    hidden_size=128,\n",
    "    n_layers=1,\n",
    "    dropout_rate=0.1,\n",
    "    EncoderCls=Encoder,\n",
    "    DecoderCls=Decoder,\n",
    "    tie_projection=True,\n",
    "    )\n",
    "\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thence thenceˈˈˈˈˈˈˈˈ', 'qurˈˈˈˈˈˈˈˈˈ']\n"
     ]
    }
   ],
   "source": [
    "with logger.log(), torch.no_grad():\n",
    "    model.cuda().eval()\n",
    "    print(model.predict(\n",
    "            ['recipe title: how to deal with bugs on your computer',\n",
    "             'directions: get rid of windows and install linux'],\n",
    "            nsteps=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Seq2Seq                                  [32, 5, 30522]            --\n",
       "├─Embedding: 1-1                         [32, 198, 128]            (3,906,816)\n",
       "├─Encoder: 1-2                           --                        --\n",
       "│    └─Dropout: 2-1                      [32, 198, 128]            --\n",
       "│    └─GRU: 2-2                          [6336, 256]               198,144\n",
       "├─Embedding: 1-3                         [1, 128]                  (recursive)\n",
       "├─Decoder: 1-4                           --                        (recursive)\n",
       "│    └─Linear: 2-3                       [32, 128]                 32,896\n",
       "├─Decoder: 1-5                           [32, 128]                 32,896\n",
       "│    └─GRU: 2-4                          [32, 1, 128]              197,376\n",
       "├─Sequential: 1-6                        [32, 30522]               --\n",
       "│    └─Linear: 2-5                       [32, 128]                 16,512\n",
       "│    └─ReLU: 2-6                         [32, 128]                 --\n",
       "│    └─Linear: 2-7                       [32, 30522]               (3,906,816)\n",
       "├─Decoder: 1-7                           [32, 128]                 (recursive)\n",
       "│    └─GRU: 2-8                          [32, 1, 128]              (recursive)\n",
       "├─Sequential: 1-8                        [32, 30522]               (recursive)\n",
       "│    └─Linear: 2-9                       [32, 128]                 (recursive)\n",
       "│    └─ReLU: 2-10                        [32, 128]                 --\n",
       "│    └─Linear: 2-11                      [32, 30522]               (recursive)\n",
       "├─Decoder: 1-9                           [32, 128]                 (recursive)\n",
       "│    └─GRU: 2-12                         [32, 1, 128]              (recursive)\n",
       "├─Sequential: 1-10                       [32, 30522]               (recursive)\n",
       "│    └─Linear: 2-13                      [32, 128]                 (recursive)\n",
       "│    └─ReLU: 2-14                        [32, 128]                 --\n",
       "│    └─Linear: 2-15                      [32, 30522]               (recursive)\n",
       "├─Decoder: 1-11                          [32, 128]                 (recursive)\n",
       "│    └─GRU: 2-16                         [32, 1, 128]              (recursive)\n",
       "├─Sequential: 1-12                       [32, 30522]               (recursive)\n",
       "│    └─Linear: 2-17                      [32, 128]                 (recursive)\n",
       "│    └─ReLU: 2-18                        [32, 128]                 --\n",
       "│    └─Linear: 2-19                      [32, 30522]               (recursive)\n",
       "├─Decoder: 1-13                          [32, 128]                 (recursive)\n",
       "│    └─GRU: 2-20                         [32, 1, 128]              (recursive)\n",
       "├─Sequential: 1-14                       [32, 30522]               (recursive)\n",
       "│    └─Linear: 2-21                      [32, 128]                 (recursive)\n",
       "│    └─ReLU: 2-22                        [32, 128]                 --\n",
       "│    └─Linear: 2-23                      [32, 30522]               (recursive)\n",
       "==========================================================================================\n",
       "Total params: 8,291,456\n",
       "Trainable params: 477,824\n",
       "Non-trainable params: 7,813,632\n",
       "Total mult-adds (Units.GIGABYTES): 322.18\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 58.89\n",
       "Params size (MB): 33.03\n",
       "Estimated Total Size (MB): 91.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torchinfo.summary(model, input_data=next(dataloaders['train'].__iter__())['input_ids'], nsteps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Цикл обучения и другие рутины, тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDTYPE = torch.int32\n",
    "FDTYPE = torch.float32 \n",
    "FDTYPE2 = torch.half\n",
    "# С сокращёнными типами проблема - нет поддержки дропаута \"из коробки\"\n",
    "FDTYPE3 = torch.float8_e4m3fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientCatcher:\n",
    "\n",
    "    epoch_criterion = lambda epoch: True\n",
    "    batch_criterion = lambda batch: batch == 0\n",
    "    reduction = lambda grad: abs(grad).mean().item()\n",
    "    \n",
    "    @classmethod\n",
    "    def write_grads(cls, epoch, batch, model: nn.Module, path):\n",
    "        \n",
    "        if cls.epoch_criterion(epoch) and cls.batch_criterion(batch):\n",
    "\n",
    "            msg = f\">>> EPOCH {epoch}, batch {batch} ::::: {time.asctime(time.gmtime())} \\n\"\n",
    "                \n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    grad = cls.reduction(param.grad.detach().cpu())\n",
    "                else: grad = None\n",
    "                    \n",
    "                msg+= f\"\\t{name}: {cls.fmt(grad)}\\n\"\n",
    "            \n",
    "            msg += f\"\\n\"            \n",
    "            with open(path, 'a') as f: f.write(msg)  \n",
    "\n",
    "    @staticmethod\n",
    "    def fmt(grad):\n",
    "        if grad is None: return None\n",
    "        elif isinstance(grad, float): return f\"{grad:.2e}\"\n",
    "        elif isinstance(grad, torch.Tensor): return f\"{grad}\"\n",
    "        else:\n",
    "            try: msg = f\"{grad}\"\n",
    "            except: msg = \"unk\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "\n",
    "    eval_fns: Dict[str, callable] = {}\n",
    "\n",
    "    max_len = 8192\n",
    "    \n",
    "    @classmethod\n",
    "    def evaluation(cls, model, dataloaders, epoch, history):\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            history['train_score'] = {}\n",
    "            history['val_score'] = {}\n",
    "            for name, fn in eval_fns.items():\n",
    "                \n",
    "                eval_train = cls.eval_fn_dl(model, dataloaders['train'])\n",
    "                eval_val = cls.eval_fn_dl(model, dataloaders['val'])\n",
    "                \n",
    "                history['train_score'][name].append(eval_train)\n",
    "                history['val_score'][name].append(eval_test)\n",
    "     \n",
    "        history['epochs'].append(epoch)\n",
    "\n",
    "    @classmethod\n",
    "    def init_history(cls, history=None):\n",
    "        if history is None: history={}\n",
    "        if 'train_score' not in history:\n",
    "            history['train_score'] = {}\n",
    "        if 'val_score' not in history:\n",
    "            history['val_score'] = {}\n",
    "        for\n",
    "\n",
    "    @classmethod\n",
    "    def eval_on_dl(cls, model, loader, score_fn):\n",
    "\n",
    "        model.eval()\n",
    "        score = 0\n",
    "        n_tokens = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                \n",
    "                pred = model(batch['input_ids'])\n",
    "                score += cls.score_fn(pred['tokens'], batch['labels']).item()\n",
    "                n_tokens += sum(batch['attention_mask'])\n",
    "                \n",
    "                if n_tokens > cls.max_len: break\n",
    "\n",
    "        if n_tokens == 0:\n",
    "            print('warning: got n_tokens=0 during evaluation,\\\n",
    "                setting n_tokens to batch_size*seq_len')\n",
    "            n_tokens = 1\n",
    "            \n",
    "        return score / n_tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainVis:\n",
    "\n",
    "    in_notebook = True\n",
    "    \n",
    "    def __init__(self, dataloaders, n_examples=2, in_notebook=True):\n",
    "        if not cls.in_notebook: plt.ion()\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def show_samples(cls, model, samples, maxlen=32):\n",
    "        tqdm.write(f\"Processing item {0}\")\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def plot_history(cls, history, model=None):\n",
    "\n",
    "        if cls.in_notebook:\n",
    "            from IPython.display import clear_output\n",
    "            clear_output(wait=True)\n",
    "        else:\n",
    "            plt.close('all')\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        axes[0].plot(history['train_loss'], label='train loss')\n",
    "        axes[0].set_xlabel('Epochs')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "\n",
    "        axes[1].plot(history['epochs'], history['train_score'], label='train score')\n",
    "        axes[1].plot(history['epochs'], history['val_score'], label='val score')\n",
    "        axes[1].set_xlabel('Epochs')\n",
    "        axes[1].set_ylabel('Score')\n",
    "        axes[1].legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if hasattr(model, 'vis_ax') and model.vis_ax is not None:\n",
    "            fig.axes.append(model.vis_ax)\n",
    "\n",
    "        if cls.in_notebook: plt.show()\n",
    "        else: plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    score_fn = None\n",
    "    eval_int = 1\n",
    "    \n",
    "    gradient_log = GradientCatcher\n",
    "    evaluation = Evaluation\n",
    "    visualisation = TrainVis\n",
    "\n",
    "    grads_path = ''\n",
    "\n",
    "    checkpoint = lambda epoch: epoch % 5\n",
    "    \n",
    "    @classmethod\n",
    "    def train(\n",
    "        cls, \n",
    "        model, \n",
    "        optimizer,\n",
    "        loss,\n",
    "        dataloaders: Dict[str, DataLoader],\n",
    "        n_epochs = 30, \n",
    "        plot = False,\n",
    "        grads = False,\n",
    "        evals = True,\n",
    "        ):\n",
    "        \n",
    "        history = {'train_loss': [], 'train_score':[], 'val_score': [], 'epochs': []}\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            model.train()\n",
    "            history['train_loss'].append(0)\n",
    "            print(f'Epoch: {epoch}')\n",
    "            \n",
    "            for i, batch in enumerate(tqdm.tqdm(dataloaders['train'])):\n",
    "\n",
    "                # YOUR CODE\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if model.teacher_forcing: model.teacher_forcing.load_batch(batch['labels'])\n",
    "\n",
    "                seq_len = batch['labels'].shape[1]\n",
    "                mask = batch['input_mask']\n",
    "                pred = model.forward(batch['input_ids'], src_mask=mask, nsteps=seq_len)\n",
    "                \n",
    "                seq_len = pred['logits'].shape[1]\n",
    "                logits = pred['logits'].contiguous().view(-1, model.vocab_size)\n",
    "                correct_tokens = batch['labels'][:, :seq_len].contiguous().view(-1)\n",
    "                loss_train = loss(logits, correct_tokens)\n",
    "                loss_train.backward()\n",
    "                history['train_loss'][-1] += loss_train.item()\n",
    "                if cls.gradient_log and grads:\n",
    "                    cls.gradient_log.write_grads(\n",
    "                        epoch, i, model, f'{cls.grads_path}{model.__class__.__name__}_grads.txt')\n",
    "                    \n",
    "                optimizer.step()\n",
    "\n",
    "            if cls.evaluation:\n",
    "                cls.evaluation.evaluate(history)\n",
    "\n",
    "            if cls.visualisation:\n",
    "                cls.visualisation.main(history)\n",
    "                \n",
    "        return history        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcing:\n",
    "\n",
    "    min_tf_ratio = 0.1\n",
    "    \n",
    "    def __init__(self, embedding, tf_ratio=0.9):\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.tf_ratio = tf_ratio\n",
    "        self.true_tokens = None\n",
    "        self.batch_size = None\n",
    "\n",
    "    @logger.trace('TF')\n",
    "    def __call__(self, i, prev) -> torch.Tensor:\n",
    "\n",
    "        # YOUR CODE\n",
    "        if self.true_tokens is None:\n",
    "            raise AttributeError('cls.true_tokens are not initialised')\n",
    "            \n",
    "        tf_idxs = torch.rand(self.batch_size) < self.tf_ratio\n",
    "        prev[tf_idxs, ...] = self.embedding(self.true_tokens[tf_idxs, i].to(device=prev.device))\n",
    "        return prev\n",
    "\n",
    "    def load_batch(self, true_tokens) -> None:\n",
    "\n",
    "        # YOUR CODE\n",
    "        self.true_tokens = true_tokens\n",
    "        self.batch_size = true_tokens.shape[0]\n",
    "\n",
    "    def update_by_score(self, score):\n",
    "        self.tf_ratio = max(self.min_tf_ratio, 1 - score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "Training set size: 76\n",
      "Validation set size: 10\n",
      "Test set size: 10\n",
      "Using batching with padding. Ensure your training loop can handle batched data!\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.01s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Evaluation' has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[356]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;129m@logger\u001b[39m.trace(\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_wrapper\u001b[39m(pred, true):\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [loss(pred, true)]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[354]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(cls, model, optimizer, loss, dataloaders, n_epochs, plot, grads, evals)\u001b[39m\n\u001b[32m     55\u001b[39m     optimizer.step()\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.evaluation:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m(history)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.visualisation:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mcls\u001b[39m.visualisation.main(history)\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'Evaluation' has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "# Проверяем \n",
    "\n",
    "DEVICE = 'cuda'\n",
    "dataloaders = get_dataloaders(copy_dataset, batch_size=32, load_ratio=2e-3, device=DEVICE)\n",
    "\n",
    "CONFIG = {'tokenizer': tokenizer, 'embedding':bert_word_embedding, 'hidden_size': 64, 'n_layers': 1, \n",
    "          'dropout_rate': 0.1, 'EncoderCls': Encoder, 'DecoderCls': Decoder, 'tie_projection': True}\n",
    "\n",
    "model = Seq2Seq(**CONFIG)\n",
    "model.to(device=DEVICE, dtype=FDTYPE)\n",
    "\n",
    "model.teacher_forcing =  TeacherForcing(model.embedding, 0.9)\n",
    "opt = optim.AdamW(model.parameters(), lr=1e-2)\n",
    "loss = nn.NLLLoss(reduction='mean', ignore_index=0)\n",
    "\n",
    "@logger.trace('loss')\n",
    "def loss_wrapper(pred, true):\n",
    "    return [loss(pred, true)]\n",
    "\n",
    "Trainer.train(model, opt, loss, dataloaders, 5, grads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "Training set size: 76\n",
      "Validation set size: 10\n",
      "Test set size: 10\n",
      "Using batching with padding. Ensure your training loop can handle batched data!\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.236706733703613\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.245777130126953\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.24075984954834\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.216809272766113\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.242348670959473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [30.236706733703613,\n",
       "  30.245777130126953,\n",
       "  30.24075984954834,\n",
       "  30.216809272766113,\n",
       "  30.242348670959473],\n",
       " 'train_score': [],\n",
       " 'val_score': [],\n",
       " 'epochs': []}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пробуем запустить модель на небольшой выборке\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "dataloaders = get_dataloaders(copy_dataset, batch_size=32, load_ratio=2e-3, device=DEVICE)\n",
    "\n",
    "model = Seq2Seq(**CONFIG)\n",
    "\n",
    "model.to(device=DEVICE)\n",
    "\n",
    "opt = optim.RMSprop(model.parameters(), lr=3e-10)\n",
    "loss = nn.NLLLoss(reduction='mean', ignore_index=0)\n",
    "\n",
    "Trainer.train(model, opt, dataloaders, loss, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.94814395904541\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.771048545837402\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.33122444152832\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.23267650604248\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.205735206604004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [26.94814395904541,\n",
       "  25.771048545837402,\n",
       "  25.33122444152832,\n",
       "  25.23267650604248,\n",
       "  25.205735206604004],\n",
       " 'train_score': [],\n",
       " 'val_score': [],\n",
       " 'epochs': []}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = optim.AdamW(model.parameters(), lr=3e-3)\n",
    "Trainer.train(model, opt, dataloaders, loss, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: This was made from Thanksgiving leftovers, and ingredients in my pantry. It's a family favorite and a hit at Pot lucks. With leftovers, it's a breeze, made from scratch ... it's work. Either way it's a hit and well worth the time. After a holiday meal half the work is done because you usually have the mashed potatoes, and turkey. When I make it from scratch, I usually use chicken rather than turkey. Prep times are from leftovers.\n",
      "ingredients: [1 pound cooked turkey meat, shredded, 1 onion, chopped, 1 (14.5 ounce) can green beans, drained, 1 (10.75 ounce) can condensed cream of mushroom soup, 8 ounces cubed Cheddar cheese, 8 ounces shredded Cheddar cheese, 4 cups prepared mashed potatoes]\n",
      "['± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± ±']\n",
      "description: This was made from Thanksgiving leftovers, and ingredients in my pantry. It's a family favorite and a hit at Pot lucks. With leftovers, it's a breeze, made from scratch ... it's work. Either way it's a hit and well worth the time. After a holiday meal half the work is done because you usually have the mashed potatoes, and turkey. When I make it from scratch, I usually use chicken rather than turkey. Prep times are from leftovers.\n",
      "ingredients: [1 pound cooked turkey meat, shredded, 1 onion, chopped, 1 (14.5 ounce) can green beans, drained, 1 (10.75 ounce) can condensed cream of mushroom soup, 8 ounces cubed Cheddar cheese, 8 ounces shredded Cheddar cheese, 4 cups prepared mashed potatoes]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "idx = 1\n",
    "text = dataloaders['train'].dataset[idx][0]\n",
    "print(text)\n",
    "print(model.predict(text))\n",
    "print(dataloaders['train'].dataset[idx][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8d6zRUeDN-k"
   },
   "source": [
    "# 3.3. Seq2seq с вниманием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ySfjzTvvDgBr"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Implements Bahdanau attention\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        \n",
    "        # Поскольку в энкодере двунаправленный GRU, key_size = 2*hidden_size\n",
    "        key_size = 2 * hidden_size if key_size is None else key_size\n",
    "        query_size = hidden_size if query_size is None else query_size\n",
    "\n",
    "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
    "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
    "        \n",
    "        self.scores = None\n",
    "        \n",
    "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
    "        assert mask is not None, \"mask is required\"\n",
    "\n",
    "        query = self.query_layer(query)\n",
    "        \n",
    "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        \n",
    "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
    "        \n",
    "        self.scores = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        context = torch.bmm(self.scores, value)\n",
    "        \n",
    "        # context shape: [B, 1, 2D], scores shape: [B, 1, M]\n",
    "        return context, self.scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderAttn(nn.Module):\n",
    "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
    "    \n",
    "    def __init__(self, context_size, hidden_size, num_layers=1, dropout=0.5,\n",
    "                 max_steps = 256,\n",
    "                 bridge=True):\n",
    "        \n",
    "        super(DecoderAttn, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout                 \n",
    "        self.rnn = nn.GRU(context_size + hidden_size, hidden_size, num_layers,\n",
    "                          batch_first=True, dropout=dropout)\n",
    "                 \n",
    "        # Для инициализации из конечного состояния энкодера\n",
    "        self.bridge = nn.Linear(context_size, hidden_size, bias=True) if bridge else None\n",
    "\n",
    "    @logger.trace('DEC')\n",
    "    def forward(self, context, prev, attention_mask=None, ):\n",
    "        \"\"\"\n",
    "        Unroll the decoder for a batch of text sequences\n",
    "\n",
    "        Args:\n",
    "            - context: torch.Tensor [B, CONTEXT]\n",
    "            - prev: torch.Tensot [B, ] initial vector or prediction on previous step\n",
    "        \"\"\"\n",
    "        ## Attention will be here\n",
    "        context, scores = self.attention(context, prev)\n",
    "        # hidden = self.init_hidden(encoder_hidden)\n",
    "\n",
    "        x = torch.cat((context, prev), dim = -1)\n",
    "        \n",
    "        output, hidden = self.rnn(x) \n",
    "        # [B, CON+HIDDEN*dec_bidir], [N_layers*dec_bidir, B, EMB_DIM], \n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    @logger.trace('DEC_hid_init')\n",
    "    def init_hidden(self, encoder_hidden):\n",
    "        \"\"\"Returns the initial decoder state,\n",
    "        conditioned on the final encoder state.\"\"\"\n",
    "    \n",
    "        if encoder_hidden is None:\n",
    "            return None  \n",
    "\n",
    "        return torch.tanh(self.bridge(encoder_hidden))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Seq2Seq                                  --\n",
       "├─Embedding: 1-1                         (3,906,816)\n",
       "├─Encoder: 1-2                           --\n",
       "│    └─GRU: 2-1                          49,920\n",
       "├─DecoderAttn: 1-3                       --\n",
       "│    └─BahdanauAttention: 2-2            --\n",
       "│    │    └─Linear: 3-1                  32,768\n",
       "│    │    └─Linear: 3-2                  16,384\n",
       "│    │    └─Linear: 3-3                  128\n",
       "│    └─GRU: 2-3                          222,720\n",
       "│    └─Linear: 2-4                       8,320\n",
       "├─Sequential: 1-4                        --\n",
       "│    └─Linear: 2-5                       16,512\n",
       "│    └─ReLU: 2-6                         --\n",
       "│    └─Linear: 2-7                       (3,906,816)\n",
       "=================================================================\n",
       "Total params: 8,160,384\n",
       "Trainable params: 346,752\n",
       "Non-trainable params: 7,813,632\n",
       "================================================================="
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    embedding=bert_word_embedding,\n",
    "    hidden_size=32,\n",
    "    n_layers=2,\n",
    "    dropout=0.8,\n",
    "    EncoderCls=Encoder,\n",
    "    DecoderCls=DecoderAttn,\n",
    "    tie_projection=True,\n",
    "    )\n",
    "\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "Training set size: 3840\n",
      "Validation set size: 480\n",
      "Test set size: 480\n",
      "Using batching with padding. Ensure your training loop can handle batched data!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'logits': tensor([[-10.3262, -10.1977, -10.1731,  ..., -10.2428, -10.1643,  -9.9575],\n",
       "          [-10.3044, -10.1660, -10.2166,  ..., -10.2189, -10.2312, -10.0540],\n",
       "          [-10.3176, -10.1856, -10.2107,  ..., -10.2145, -10.1270,  -9.9311],\n",
       "          ...,\n",
       "          [-10.3294, -10.0187, -10.0757,  ..., -10.1528, -10.0206,  -9.7271],\n",
       "          [-10.3633, -10.1294, -10.0995,  ..., -10.1705, -10.1223,  -9.6301],\n",
       "          [-10.3461, -10.0450, -10.0799,  ..., -10.1719, -10.0573,  -9.9318]],\n",
       "         device='cuda:0', grad_fn=<ViewBackward0>),\n",
       "  'loss': [tensor(10.3298, device='cuda:0', grad_fn=<NllLossBackward0>)]},\n",
       " 1: {'logits': tensor([[-10.2669, -10.1956, -10.1794,  ..., -10.2711, -10.2145,  -9.9505],\n",
       "          [-10.2847, -10.1509, -10.2222,  ..., -10.3808, -10.2322, -10.1173],\n",
       "          [-10.2951, -10.2053, -10.1702,  ..., -10.2230, -10.2693, -10.0974],\n",
       "          ...,\n",
       "          [-10.2345, -10.1131, -10.0416,  ..., -10.2350, -10.2673, -10.0906],\n",
       "          [-10.2721, -10.1124, -10.1379,  ..., -10.2327, -10.2376, -10.1729],\n",
       "          [-10.2564, -10.1683, -10.1480,  ..., -10.3206, -10.1844, -10.1204]],\n",
       "         device='cuda:0', grad_fn=<ViewBackward0>),\n",
       "  'loss': [tensor(10.1849, device='cuda:0', grad_fn=<NllLossBackward0>)]}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "dataloaders = get_dataloaders(copy_dataset, batch_size=3, load_ratio=0.1, device=DEVICE)\n",
    "model = Seq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    embedding=bert_word_embedding,\n",
    "    hidden_size=128,\n",
    "    n_layers=2,\n",
    "    dropout=0.5,\n",
    "    EncoderCls=Encoder,\n",
    "    DecoderCls=DecoderAttn,\n",
    "    tie_projection=True,\n",
    ")\n",
    "\n",
    "model.to(device=DEVICE)\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss = nn.NLLLoss(reduction='mean', ignore_index=0)\n",
    "\n",
    "@logger.trace('loss')\n",
    "def loss_wrapper(pred, true):\n",
    "    return [loss(pred, true)]\n",
    "\n",
    "check_batch_forward(model, loss_wrapper, opt, dataloaders['train'], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "Training set size: 76\n",
      "Validation set size: 10\n",
      "Test set size: 10\n",
      "Using batching with padding. Ensure your training loop can handle batched data!\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.5140733718872\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.24296379089355\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.28668594360352\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.13638019561768\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.11091327667236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [214.5140733718872,\n",
       "  214.24296379089355,\n",
       "  214.28668594360352,\n",
       "  214.13638019561768,\n",
       "  214.11091327667236],\n",
       " 'train_score': [],\n",
       " 'val_score': [],\n",
       " 'epochs': []}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders = get_dataloaders(copy_dataset, batch_size=3, load_ratio=2e-3, device=DEVICE)\n",
    "\n",
    "model.teacher_forcing =  TeacherForcing(model.embedding, 1.0)\n",
    "model.to(device=DEVICE)\n",
    "\n",
    "opt = optim.AdamW(model.parameters(), lr=3e-3)\n",
    "loss = nn.NLLLoss(reduction='mean', ignore_index=0)\n",
    "\n",
    "Trainer.train(model, opt, dataloaders, loss, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.train(model, opt, dataloaders, loss, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearch:\n",
    "\n",
    "    @classmethod\n",
    "    def run(ModelClass, parameter_grid):\n",
    "        \n",
    "        \n",
    "\n",
    "    def "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bp_g1_IkDrGz"
   },
   "source": [
    "# 5. Контрольные вопросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlACumeWDvxV"
   },
   "outputs": [],
   "source": [
    "# Насколько корректно модель предсказывает рецепты из тренировочной выборки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOkcdsQWD_7Y"
   },
   "outputs": [],
   "source": [
    "# Насколько корректно модель предсказывает рецепты из тестовой выборки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5subBxpEH90"
   },
   "outputs": [],
   "source": [
    "# Что будет, если подать рецепт из категорий, на которых модель не обучалась?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zthbgR3lEeao"
   },
   "outputs": [],
   "source": [
    "# Что будет, если подать промпт, не предполагающйий наличие рецепта?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
