{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c1b6a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import Tuple, List, Dict, Sized, Optional, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0511b5b2",
   "metadata": {},
   "source": [
    "## 1. Выбор метрик\n",
    "\n",
    "В задачах бинарной классификации существует 4 типа меток:\n",
    "- *Истинно положительные (True Positives, TP)* - правильно предсказанные положительные метки;\n",
    "- *Истинно отрицательные (True Negatives, TN)* - правильно предсказанные отрицательные метки;\n",
    "- *Ложно положительные (False Positives, FP)* - ошибочно предсказанные положительные метки;\n",
    "- *Ложно отрицательные (False Negatives, FN)* - ошибочно предсказанные отрицательные метки;\n",
    "\n",
    "Для ***идеальной*** модели машинного обучения\n",
    "$$ \\text{FN}=\\text{FP}=0 $$\n",
    "\n",
    "Однако для реальных моделей множества FN и FP всегда не пустые *(а если пустые - нужно постараться отыскать такие новые данные, чтобы они стали непустыми)* и условная стоимость ошибки может варьироваться.\n",
    "\n",
    "Примеры:\n",
    "- Модель выявляет рак - FN или FP дороже?\n",
    "- Модель определяет, является ли письмо спамом - FN или FP дороже?\n",
    "- В суде FN или FP дороже?\n",
    "\n",
    "Метрика Accuracy, по определению, никак не учитывает различия между этими классами:\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP}+\\text{TN}}{\\text{Total}} = \\frac{\\text{TP}+\\text{TN}}{\\text{TP}+\\text{TN}+\\text{FP}+\\text{FN}} \n",
    "$$\n",
    "\n",
    "Поэтому при классификации, в зависимости от задачи, важно отслеживать и другие метрики:\n",
    "\n",
    "1. **Precision (точность)**: \n",
    "\n",
    "    Доля правильно предсказанных положительных меток среди всех предсказанных положительных меток:\n",
    "    $$\n",
    "    \\text{Precision} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}}\n",
    "    $$\n",
    "\n",
    "2. **Recall (отзыв)**: \n",
    "\n",
    "    Доля правильно предсказанных положительных меток среди всех фактических положительных меток:\n",
    "    $$ \n",
    "    \\text{Recall} = \\frac{\\text{TP}}{\\text{TP}+\\text{FN}} \n",
    "    $$\n",
    "\n",
    "3. **F1-мера**:\n",
    "\n",
    "    Гармоническое среднее между Precision и Recall\n",
    "    $$ \n",
    "    \\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} = \\frac{2 \\cdot \\text{TP}}{2 \\cdot \\text{TP} + \\text{FP} + \\text{FN}}\n",
    "    $$\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1913daf",
   "metadata": {},
   "source": [
    "![](../images/MetricsSummary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c88882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def generate_synthetic_data(n_samples=1000, class_balance=0.5):\n",
    "    \"\"\"\n",
    "    Generates synthetic data for a binary classification problem.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): Total number of samples to generate.\n",
    "        class_balance (float): The proportion of the positive class (class 1).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Features (X).\n",
    "        torch.Tensor: Labels (y).\n",
    "    \"\"\"\n",
    "    n_class_1 = int(n_samples * class_balance)\n",
    "    n_class_0 = n_samples - n_class_1\n",
    "\n",
    "    # Class 0: centered around (-2, -2)\n",
    "    class_0 = torch.randn(n_class_0, 2) - 2\n",
    "\n",
    "    # Class 1: centered around (2, 2)\n",
    "    class_1 = torch.randn(n_class_1, 2) + 2\n",
    "\n",
    "    X = torch.cat([class_0, class_1], dim=0)\n",
    "    y = torch.cat([torch.zeros(n_class_0), torch.ones(n_class_1)], dim=0).long()\n",
    "\n",
    "    # Shuffle the data\n",
    "    shuffle_indices = torch.randperm(n_samples)\n",
    "    X = X[shuffle_indices]\n",
    "    y = y[shuffle_indices]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def simulate_model_predictions(X, y, noise_level=0.5, bias_to_majority_class=0.0):\n",
    "    \"\"\"\n",
    "    Simulates the output of a binary classification model.\n",
    "\n",
    "    This function simulates logits (raw scores) from a model. A higher logit for a\n",
    "    sample means the model is more confident that it belongs to the positive class.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): Input features.\n",
    "        y (torch.Tensor): True labels.\n",
    "        noise_level (float): How \"good\" the model is. Lower noise means a better model.\n",
    "        bias_to_majority_class (float): A factor to simulate a model biased towards\n",
    "                                       predicting the majority class.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Simulated logits (raw model scores).\n",
    "    \"\"\"\n",
    "    # A perfect model would output scores based on the true centers.\n",
    "    # We simulate a real model by adding noise.\n",
    "    perfect_scores = (X[:, 0] + X[:, 1]) / 2  # Simple linear separation\n",
    "    noise = torch.randn(X.shape[0]) * noise_level\n",
    "\n",
    "    # This bias simulates a model that has learned to favor the majority class\n",
    "    # A negative bias pushes predictions towards class 0.\n",
    "    simulated_logits = perfect_scores + noise - bias_to_majority_class\n",
    "\n",
    "    return simulated_logits\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using seaborn.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_scores, title='ROC Curve'):\n",
    "    \"\"\"\n",
    "    Plots the ROC curve and shows the AUC score.\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def print_metrics(y_true, y_pred, y_scores):\n",
    "    \"\"\"\n",
    "    Calculates and prints key classification metrics.\n",
    "    \"\"\"\n",
    "    accuracy = (y_true == y_pred).float().mean()\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    _, _, roc_auc = roc_curve(y_true, y_scores)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b180e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 1: The misleading nature of accuracy on an imbalanced dataset ---\n",
    "print(\"--- Scenario 1: Imbalanced Dataset ---\")\n",
    "print(\"We have a dataset with 95% of samples belonging to Class 0 (negative) \"\n",
    "        \"and 5% to Class 1 (positive).\")\n",
    "\n",
    "X_imbalanced, y_imbalanced = generate_synthetic_data(n_samples=1000, class_balance=0.05)\n",
    "\n",
    "# Let's simulate a \"dumb\" model that always predicts the majority class (Class 0)\n",
    "y_pred_dumb = torch.zeros(y_imbalanced.shape[0])\n",
    "# For scores, let's assume it gives a low score for all samples\n",
    "y_scores_dumb = torch.full((y_imbalanced.shape[0],), -1.0)\n",
    "\n",
    "\n",
    "print(\"\\nMetrics for a 'Dumb' Model (always predicts majority class 0):\")\n",
    "print_metrics(y_imbalanced, y_pred_dumb, y_scores_dumb)\n",
    "plot_confusion_matrix(y_imbalanced, y_pred_dumb, title=\"Confusion Matrix for 'Dumb' Model\")\n",
    "\n",
    "print(\"\\nObservation:\")\n",
    "print(\"The accuracy is very high (95%)! However, the model is useless.\")\n",
    "print(\"It completely fails to identify any positive samples (Recall = 0.0).\")\n",
    "print(\"Precision is also 0.0 because it never makes a positive prediction.\")\n",
    "print(\"This shows why accuracy is not a good metric for imbalanced problems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ba068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 2: A slightly better model on the same imbalanced dataset ---\n",
    "print(\"\\n--- Scenario 2: A 'Better' Model on the Imbalanced Dataset ---\")\n",
    "# This model has some predictive power but is biased towards the majority class.\n",
    "y_scores_better = simulate_model_predictions(X_imbalanced, y_imbalanced, noise_level=1.5, bias_to_majority_class=1.0)\n",
    "y_pred_better = (y_scores_better > 0).float() # Threshold at 0\n",
    "\n",
    "print(\"\\nMetrics for the 'Better' Model:\")\n",
    "print_metrics(y_imbalanced, y_pred_better, y_scores_better)\n",
    "plot_confusion_matrix(y_imbalanced, y_pred_better, title=\"Confusion Matrix for 'Better' Model\")\n",
    "\n",
    "print(\"\\nObservation:\")\n",
    "print(\"Accuracy is still high, but now we have non-zero precision and recall.\")\n",
    "print(\"The F1-score gives a single number to balance Precision and Recall.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c6fce",
   "metadata": {},
   "source": [
    "Перечисленные метрики в случае бинарной классификации зависят от порога классификации (classification treshold).\n",
    "\n",
    "Лучше всего понять качество классификационной модели позволяет **ROC кривая**:\n",
    "\n",
    "**ROC-кривая** (Receiver Operating Characteristic) отображает соотношение истинных положительных показателей к ложным положительным показателям при различных порогах.\n",
    "\n",
    "**AUC** (Area Under Curve) представляет собой площадь под ROC-кривой и измеряет общую эффективность классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_imbalanced, y_scores_better, title=\"ROC Curve for 'Better' Model\")\n",
    "print(\"The ROC-AUC score (Area Under the Curve) is a great summary metric.\")\n",
    "print(\"It measures the model's ability to distinguish between the two classes across all possible thresholds.\")\n",
    "print(\"An AUC of 0.5 is random guessing, and 1.0 is a perfect model. Our 0.88 is quite good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Scenario 3: Precision vs. Recall Trade-off ---\n",
    "print(\"\\n--- Scenario 3: The Precision-Recall Trade-off ---\")\n",
    "print(\"By changing the classification threshold, we can trade Precision for Recall.\")\n",
    "print(\"A high threshold makes the model more 'cautious' about predicting Class 1 (higher Precision, lower Recall).\")\n",
    "print(\"A low threshold makes the model predict Class 1 more often (lower Precision, higher Recall).\")\n",
    "\n",
    "# High threshold -> High Precision\n",
    "y_pred_high_precision = (y_scores_better > 2.0).float()\n",
    "print(\"\\nMetrics with a HIGH threshold (2.0):\")\n",
    "print_metrics(y_imbalanced, y_pred_high_precision, y_scores_better)\n",
    "\n",
    "# Low threshold -> High Recall\n",
    "y_pred_high_recall = (y_scores_better > -1.0).float()\n",
    "print(\"\\nMetrics with a LOW threshold (-1.0):\")\n",
    "print_metrics(y_imbalanced, y_pred_high_recall, y_scores_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682ab91",
   "metadata": {},
   "source": [
    "## 2. Стохастическое усреднение весов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eac7b7",
   "metadata": {},
   "source": [
    "![](../images/SWA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c875f05d",
   "metadata": {},
   "source": [
    "## 3. SWIN Трансформер"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d5ae1",
   "metadata": {},
   "source": [
    "Изображения в датасете CIFAR10 достаточно были достаточно маленькими - всего 32х32\n",
    "\n",
    "При применении ViT с той же архитектурой к изображениям с высоким разрешением, мы столкнёмся со следующей проблемой:\n",
    "\n",
    "- *Количество* патчей растёт пропорционально квадрату разрешения, а количество операций внимания - пропорционально квадрату числа патчей. Итого для картинок с разрешением в x раз больше понадобится в x^4 раз больше операций внимания:\n",
    "$$\n",
    "\\Omega (\\text{MSA}) = 4hwC^2 + 2(hw)^2 C\n",
    "$$\n",
    "\n",
    "- Если же увеличивать *размер* патчей, снижается способность модели обрабатывать мелкие детали - годится для классификации, но не для задач детекции и сегментации.\n",
    "\n",
    "Одна из архитектур, успешно решающих данную проблему - Shifted Window Transformer: \n",
    "https://arxiv.org/pdf/2103.14030"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487169c6",
   "metadata": {},
   "source": [
    "![](../images/SWIN_Transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4737d8b",
   "metadata": {},
   "source": [
    "Эта архитектура базируется на двух основных идеях:\n",
    "\n",
    "**Patch Merging**: \n",
    "\n",
    "В каждом следующем блоке модели (обозначен пунктиром) соседние патчи объединяются в один блоками 2х2 - они конкатенируются по размерности вложения, после чего эта размерность понижается с помощью небольшого обучаемого слоя (линейного, например).\n",
    "\n",
    "Такой механизм даёт модели иерархическое представление изображение, которое позволяет хорошо решать задачи сешментации, детекции и т.д.:\n",
    "\n",
    "![](../images/SWIN_patch_merging.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17667a0",
   "metadata": {},
   "source": [
    "**Windowed self-attention and shifted windowed self-attention:**\n",
    "\n",
    "В модель уже зашит механизм для работы с признаками изображения на разных уровнях - это позволяет без потери качества перейти к обработке токенов в рамках небольших локальных окон (windowed attention).\n",
    "\n",
    "![](../images/SWIN_window.jpg)\n",
    "\n",
    "Такой подход уже применялся при обработке языка, например, в модели Longformer. Но есть особенность - чтобы обеспечить взаимодействие между окнами, на следующем шаге считается MHSA для сдвинутых по диагонали окон:\n",
    "\n",
    "![](../images/SWIN_shifted_window_msa.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33043d2c",
   "metadata": {},
   "source": [
    "### Реализуем SWIN Transformer с нуля.\n",
    "\n",
    "Кроме перечисленных модулей, отличие от уже реализованного ViT в том, что нам удобнее делать flattening патчей непосредственно перед MHSA - т.е. в основном модель будет работать с размерностью batch, h_patches, w_patches, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed50b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Rotary Positional Embeddings for Transformers.\n",
    "\n",
    "    This module applies rotary positional embeddings to input tensors, allowing the model to utilize \n",
    "    continuous position information in a more flexible manner compared to traditional learned embeddings.\n",
    "\n",
    "    :param d: Dimension of the embeddings. Should be even.\n",
    "    :param base: Base used for calculating positional encodings (default: 10,000).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d: int, base: int = 10_000):\n",
    "        super().__init__()\n",
    "        if d % 2 != 0:\n",
    "            raise ValueError(\"Dimension `d` for Rotary Positional Embedding must be even.\")\n",
    "        self.base = base\n",
    "        self.d = d\n",
    "        self.cos_cached = None\n",
    "        self.sin_cached = None\n",
    "\n",
    "    def _build_cache(self, max_pos: int, device: torch.device, dtype: torch.dtype):\n",
    "        \"\"\"Builds the cache for cosine and sine values.\"\"\"\n",
    "        if self.cos_cached is not None and max_pos <= self.cos_cached.shape[0]:\n",
    "            return\n",
    "\n",
    "        theta = 1. / (self.base ** (torch.arange(0, self.d, 2).float() / self.d)).to(device)\n",
    "        seq_idx = torch.arange(max_pos, device=device, dtype=dtype)\n",
    "        idx_theta = torch.einsum('n,d->nd', seq_idx, theta)\n",
    "        idx_theta2 = torch.cat([idx_theta, idx_theta], dim=1)\n",
    "\n",
    "        self.cos_cached = idx_theta2.cos()\n",
    "        self.sin_cached = idx_theta2.sin()\n",
    "\n",
    "    @staticmethod\n",
    "    def _rotate_half(x: torch.Tensor):\n",
    "        \"\"\"Rotates half of the embedding dimension.\"\"\"\n",
    "        x1, x2 = x.chunk(2, dim=-1)\n",
    "        \n",
    "        return torch.cat([-x2, x1], dim=-1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pos: torch.Tensor=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the Rotary Positional Embeddings.\n",
    "\n",
    "        This method applies the rotary positional embeddings to the input tensor.\n",
    "\n",
    "        :param x: Input tensor of shape [batch, seq_len, d] \n",
    "        :param pos: Optional tensor of position indices, shape [batch, seq_len]. If None, indices are inferred as range(seq_len).\n",
    "        :return: Tensor with applied rotary embeddings of the same shape as x.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "        \n",
    "        if pos is None:\n",
    "            pos = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "        max_pos = pos.max().item() + 1\n",
    "        \n",
    "        self._build_cache(max_pos, device=x.device, dtype=x.dtype)\n",
    "        \n",
    "        x_rotated = self._rotate_half(x)\n",
    "       \n",
    "        x_rope = x * self.cos_cached[pos] + x_rotated * self.sin_cached[pos]\n",
    "\n",
    "        return x_rope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RopeEmbeddingXY(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim: int, max_patches_xy: int = 128, freezed=True):\n",
    "        '''\n",
    "        :param emb_dim: \n",
    "        :param max_patches_xy:\n",
    "        :param freezed:\n",
    "        :param separate: \n",
    "        '''\n",
    "        super(RopeEmbeddingXY, self).__init__()\n",
    "        assert emb_dim % 4 == 0, f'Embedding dimension must be divisible by 4'\n",
    "        assert emb_dim > 4, f'Embedding dimension must be greater than 4'\n",
    "   \n",
    "        self.emb_dim = emb_dim\n",
    "        # self.ax_dim = emb_dim // 2 if separate else emb_dim\n",
    "        self.h_emb = RotaryPositionalEmbedding(emb_dim)\n",
    "        self.w_emb = RotaryPositionalEmbedding(emb_dim)        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        :param x: input patches [B, H, W, D]\n",
    "        :returns: output patches [B, H, W, D]\n",
    "        '''\n",
    "        batch_size, patch_h, patch_w, emb_dim = x.shape\n",
    "        device = x.device\n",
    "        \n",
    "        h_pos, w_pos = torch.meshgrid(\n",
    "            torch.arange(0, patch_h), torch.arange(0, patch_w), indexing='ij',\n",
    "        )\n",
    "\n",
    "        x = self.h_emb(x, h_pos.unsqueeze(0))\n",
    "        x = self.w_emb(x, w_pos.unsqueeze(0))\n",
    "            \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d86caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, patch_size: int, channels: int, emb_dim: int):\n",
    "        '''\n",
    "        :param patch_size: int - size of the patch square (size of convolution kernel)\n",
    "        :param channels: int - channels of input image\n",
    "        :param emb_dim: int - embedding dimension\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=channels,\n",
    "            out_channels=emb_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size,\n",
    "            )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        :param x: torch.Tensor [B, C, H, W] - batched images\n",
    "        :returns: torch.Tensor [B, D, pH, pW] - patches embeddings\n",
    "        '''\n",
    "        return self.conv(x)        \n",
    "\n",
    "\n",
    "class ImageEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, patch_size: int, in_channels: int, emb_dim: int, dropout_rate: float = 0.1, freezed_pe = True):\n",
    "        '''\n",
    "        :param patch_size: int - size of the square patch\n",
    "        :param in_channels: int - number of input channels\n",
    "        :param emb_dim: int - embedding dimension\n",
    "        :param dropout_rate: float - dropout rate\n",
    "        :param freezed_pe: bool - freeze positional embeddings\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.in_channels = in_channels\n",
    "        self.emb_dim = emb_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.freezed_pe = freezed_pe\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.img_emb = PatchEmbedding(patch_size=patch_size, channels=in_channels, emb_dim=emb_dim)\n",
    "        \n",
    "        self.pos_emb = RopeEmbeddingXY(emb_dim=emb_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        :param x: torch.Tensor [B, C, H, W] - input image\n",
    "        :returns: torch.Tensor [B, pH, pW, D] - output tokens (L=H*W//patch^2)\n",
    "        '''\n",
    "        x_patches = self.img_emb(x) # [B, D, pH, pW]\n",
    "\n",
    "        return self.pos_emb(x_patches) # SinusoidalEncodingXY expects [B, D, pH, pW]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e093ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(4 * input_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: input patches [B, H, W, D_in]\n",
    "        :returns: output patches [B, H//2, W//2, D_out]\n",
    "        '''\n",
    "        batch, patches_H, patches_W, emb_dim = x.shape\n",
    "        \n",
    "        x_tl = x[:, 0::2, 0::2, :]\n",
    "        x_tr = x[:, 0::2, 1::2, :]\n",
    "        x_bl = x[:, 1::2, 0::2, :]\n",
    "        x_br = x[:, 1::2, 1::2, :]\n",
    "        \n",
    "        x = torch.cat([x_tl, x_tr, x_bl, x_br], dim=-1)\n",
    "        \n",
    "        return self.proj(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf96a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock(nn.Module):\n",
    "     \n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n",
    "\n",
    "        self.MHSA_W = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
    "        self.MHSA_SW = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(dim_feedforward, d_model)\n",
    "        )\n",
    "\n",
    "        self.LN_W = nn.LayerNorm(d_model)\n",
    "        self.LN_SW = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        '''\n",
    "        :param x: input patches [B, H, W, D]\n",
    "        :returns: output patches [B, H, W, D]\n",
    "        '''\n",
    "\n",
    "        x = self.LN_W(x)\n",
    "\n",
    "        x_w = self.fetch_window(x)\n",
    "        x_w, _ = self.MHSA_W.forward(x_w, x_w, x_w)\n",
    "\n",
    "        x = x + self.unfetch_window(x_sw)\n",
    "\n",
    "        x = self.LN_SW(x)\n",
    "        x_sw = self.fetch_window(self.diag_shift(x, 1))\n",
    "        x_sw = self.MHSA_SW.forward(x_sw, x_sw, x_sw)\n",
    "        \n",
    "        x = x + self.diag_shift(self.unfetch_window(x_sw), -1)\n",
    "\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "    def fetch_window(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        :param x: input patches [B, H, W, D]\n",
    "        :returns: attn windows [B*4, L, D]\n",
    "        '''\n",
    "         \n",
    "        batch, patches_H, patches_W, emb_dim = x.shape\n",
    "\n",
    "        h_center = patches_H//2\n",
    "        w_center = patches_W//2\n",
    "        # [B, H, W, D] -> [4*B, L, D]\n",
    "        x_w = torch.cat([\n",
    "            x[:, :h_center, :w_center, :],\n",
    "            x[:, :h_center, w_center:, :],\n",
    "            x[:, h_center:, :w_center, :],\n",
    "            x[:, h_center:, :w_center, :],\n",
    "        ], dim=0)\n",
    "\n",
    "        return x_w \n",
    "\n",
    "    def unfetch_window(self, x: torch.Tensor):\n",
    "        '''\n",
    "        :param x: attn windows [B*4, L, D]\n",
    "        :returns: input patches [B, H, W, D]\n",
    "        '''\n",
    "         \n",
    "        batch4, l, emb_dim = x.shape\n",
    "\n",
    "        h_center = patches_H//2\n",
    "        w_center = patches_W//2\n",
    "        # [B, H, W, D] -> [4*B, L, D]\n",
    "        x_w = torch.cat([\n",
    "            x[:, :h_center, :w_center, :],\n",
    "            x[:, :h_center, w_center:, :],\n",
    "            x[:, h_center:, :w_center, :],\n",
    "            x[:, h_center:, :w_center, :],\n",
    "        ], dim=0)\n",
    "\n",
    "        return x_w \n",
    "    \n",
    "    def diag_shift(self, x: torch.Tensor):\n",
    "        '''\n",
    "        :param x: input patches [B, H, W, D]\n",
    "        :returns: output patches [B, H, W, D]\n",
    "        '''\n",
    "\n",
    "\n",
    "        batch, patches_H, patches_W, emb_dim = x.shape\n",
    "\n",
    "        return x_s \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c811c6",
   "metadata": {},
   "source": [
    "Для дальнейшего изучения:\n",
    "\n",
    "https://github.com/ZTX-100/Efficient_ViT_with_DW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
